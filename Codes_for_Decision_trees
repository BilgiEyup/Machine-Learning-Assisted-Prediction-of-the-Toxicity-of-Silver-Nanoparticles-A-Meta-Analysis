#Make sure to import the following packages to perform the analyses in the article.


!pip install dtreeviz #For decision tree visualization

import dtreeviz.trees
import pandas as pd
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt"The packages below are used for classifiers other than decision trees."
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split 
from sklearn import metrics
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn import tree
from sklearn.utils import shuffle
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    confusion_matrix,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score
)
from sklearn.utils import shuffle

#The packages below are used for classifiers other than decision trees.

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split

#to read and assign dataset to a dataframe
df = pd.read_csv('<path_of_your_dataset/dataset_name.csv',sep=',',decimal='.')

#to see column names
df.columns

#to see dataframe's head and tail
df

#To assign a new dataframe that only contains the requested columns, use the following code:
df2=df[['column_name1','column_name2','column_name3','column_name4','column_name7',]]



#"In this article, the bioactivity threshold value is determined as 50. 
#Therefore, those with cytotoxicity values of 50 or less are labeled as toxic, 
#and those above 50 are labeled as non-toxic. By updating the following code 
#according to your own threshold values, you can add these categories to a new column.

#For example, you can consider the values between 90% and 110% as non-toxic, 
#above 110% as proliferative, and between 50% and 90% as intermediate toxicity. 
#You can add these values to a list called "bioactivity_threshold" and 
#then append it to the "toxicology_class" column.

#numeric_column_name is Cell_viability for our raw dataset
bioactivity_threshold = []
for i in df2.numeric_column_name:        
  if float(i) >= 90 and float(i)<= 110:
    bioactivity_threshold.append("nontoxic")
  if float(i)>50 and float(i)<90:
    bioactivity_threshold.append('nontoxic')
  elif float(i) <= 50:
    bioactivity_threshold.append("toxic")
  elif float(i)>110:
    bioactivity_threshold.append("nontoxic")
bioactivity_class = pd.Series(bioactivity_threshold, name='toxicology_class')
df3 = pd.concat([df2, bioactivity_class], axis=1)
df4=df3[df3.toxicology_class.notna()]
df5=df4[df4.Cell_viability.notna()]
df5

#Since categorical and binary data are more useful for classification algorithms, 
#we can create a new column called 'toxicology_category' using the data in the 
#'toxicology_class' column we previously created and 
#add it to a new dataframe called df6 using the following code:

class_cat = []
for i in df5.toxicology_class:        
  if i=='toxic':
    class_cat.append("0")
  if i=='nontoxic':
    class_cat.append("1")

class_category = pd.Series(class_cat, name='toxicology_category')
df6 = pd.concat([df5, class_category], axis=1)
df6

#As an alternative, you can use this code
df6 = pd.get_dummies(df5, drop_first=True) # to create categorical versions of all columns including toxicology_class

#to drop unwanted raws you can use the code below:

df5.drop(df5.loc[df5['Concentration_category']==1].index, inplace=True) #in this article concentration divided into 9 different category, not to create bias from untreated cells we preferred to drop those raws.

#If you have numeric rows with NA values, you can discard them 
#by writing the relevant column name in the following code.
df6 = df5[df5.colum_name.notna()]


#Since toxicology_class_toxic will be the endpoint we used in the article, we can separate it from the dataframe and 
#assign it to a different variable for later use in classification.
encoded_x = df6.drop('toxicology_class_toxic', axis=1)
encoded_y=df6['toxicology_class_toxic']

#to see distributions in dataframe:

item_counts = df6["toxicology_class_toxic"].value_counts()
item_counts


#AFTER COMPLETING THE PREPARATION PROCESS, 
#WE CAN START THE ANALYSIS ON THE DATAFRAME WITH THE FOLLOWING CODES

shuffled = shuffle(df6) #To shuffle the dataframe in a way that does not create bias:
feature_cols = ['Feautre_column1','Feature_column2', 'Feature_column3', 'Feature_column4']
X = shuffled[feature_cols] # Features

y = shuffled.toxicology_class_toxic # Target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 12345, stratify = y) 
# 70% training and 30% test, 
#stratify=y ensures that the target binary variable (such as toxic=0, non-toxic=1) is distributed 
#in the test and train sets in the same proportion as it is distributed 
#throughout the entire dataframestratify=y ensures random split of data 

# Create Decision Tree classifer object
clf = DecisionTreeClassifier(max_depth=5, min_samples_leaf=15) #you can change the depth and leaf number 

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

#to get metrics 
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1score = f1_score(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
print('Precision: ',precision)
print('Recall: ', recall)
print('f1score: ', f1score)

shuffled.to_csv('<path_to_computer>/shuffled_dataset.csv')

#TO CREATE PLOT THAT SHOWS FEATURE IMPORTANCE WITH VALUES



